FLIP ROBO-MACHINE LEARNING — WORKSHEET 11 (LINEAR REGRESSION)

In Q1 to Q8, only one option is correct, Choose the correct option:

1. What happens to R’ measure if we add a new feature?

A) remains same B) always increases
C) may or may not increase D) always decreases

Ans: A

2. The correct relationship between SST, SSR and SSE is given by:

A) SSR = SST + SSE B) SST = SSR + SSE
C) SSE = SSR - SST D) None of the above

Ans: D

3. Residuals in regression analysis can be defined as:

A) difference between the actual value and the predicted value.
B) difference between the actual value and the mean of predicted value.
C) difference between the actual value and mean of dependent variable.
D) None of the above.

Ans: A

4. In a simple linear regression model, if we change the input variable by 1 unit, then how much output variable will change?

A) By 1 B) No Change
C) By its slope D) None of the above

Ans: B

5. If the coefficient of determination is equal to 1, then correlation coefficient:

A) must also be equal to 1 B) can be either -1 or 1
C) can be any value between -1 to 1 D) must be -1

Ans: A

6. Which of the following plot is best suited for the linear relationship of continuous variables?
A) Scatter plot B) Histograms
C) Pie charts D) All of the above

Ans: D

7.The ratio of MSR/MSE produces:

A) t-statistics B) f-statistics
C) z-statistics D) None of the above.

Ans: B

8. Which of the following regularizations uses only L2 normalization for its penalty parameter?
A) Lasso B) Elastic Nets
C) Ridge D) All of the above

Ans: D

In Q9 to Q11, more than one options are correct, Choose all the correct options:

9.Which of the following statement/s are true for best fitted line?

A) It shows the causal relationship between dependent and independent variables
B) It shows the positive or negative relation between dependent and independent variables
C) It always goes through origin
D) It is a straight line that is the best approximation of the given data sets

Ans: B and C

10. Regularizations helps in:

A) Reducing the training time B) Generalizing the test set
C) Automatic feature selection D) Grouping the data

Ans: C and D

11. Linear regression can be implemented through:
A) Normal Equation B) Singular Value Decomposition
C) Parity checks D) nodes

Ans: A and B

Q12 to Q15 are subjective answer type questions, Answer them briefly.

12. Explain R? and adjusted R* metrics?

Ans: R2 shows how well terms (data points) fit a curve or line and Adjusted R2 also indicates how well terms fit a curve or line, 
but adjusts for the number of terms in a model. If we add more and more useless variables to a model, adjusted r-squared will decrease.

13. Explain the cost function of linear regression?

Ans: The cost function is a simple function where we measure the difference or distance between the predicted value and the actual value. 
The cost function (may also see this referred to as loss or error.) can be estimated by iteratively running the model to compare estimated 
predictions against “ground truth” — the known values of y.  It also measures the average squared difference between an observation's actual and predicted values. 
The output is a single number representing the cost, or score, associated with our current set of weights. So here our goal is to minimize the cost function.
MSE to improve the accuracy of our model.

14. Differentiate SSE, SSR and SST.

Ans: SST is the maximum sum of squares of errors for the data because the minimum information of Y itself was only used for the baseline model.
SSR is the sum of squared deviations of predicted values (predicted using regression) from the mean value and SSE is the sum of squared deviations 
of actual values from predicted values hence as a result, the fraction of the sum of squares per one degree of freedom is approximately the same 
for regression and error terms. The difference between SST and SSR is remaining unexplained variability of Y after adopting the regression model, 
which is called as sum of squares of errors (SSE).

15. What are the various evaluation metrics for linear regression?

Ans: The various evaluation metrics used for linear regression are,
1) Mean Squared Error(MSE) 
2) Root-Mean-Squared-Error(RMSE)
3) Mean-Absolute-Error(MAE)
